#!/usr/bin/env python
import sys
import glob
import subprocess
import os
import json
import fcntl 
import numpy as np
from termcolor import colored
from joblib import Parallel, delayed
import multiprocessing

def parse_num_epochs(num_epochs, granularity=100):
    try:
        num_epochs = int(num_epochs)
        return num_epochs, (num_epochs % granularity) == 0
    except ValueError:
        return num_epochs, True

def process_result(results_path, out_file, exp_name):
    with open(results_path, 'r') as f:
        experiment = json.load(f)['performances']

    model_keys = list(experiment['fair_networks_repr'].keys())
    fair_results = [experiment['fair_networks_repr'][key] for key in model_keys]
    random_result = experiment['random_networks_repr'][model_keys[0]]
    original_results = [experiment['original_repr'][key] for key in model_keys]
    
    y_gap = [original_result['y']['val'] - fair_result['y']['val'] for fair_result, original_result in zip(fair_results, original_results)] 
    s_gap = [np.abs(random_result['s']['val'] - fair_result['s']['val']) for fair_result in fair_results]
    total_gap = min(y_gap) + min(s_gap)

    with open(out_file, 'a') as f:
        fcntl.flock(f, fcntl.LOCK_EX)
        f.write('{},{},{},{}\n'.format(exp_name, min(y_gap), min(s_gap), total_gap))
        fcntl.flock(f, fcntl.LOCK_UN)


def process_dir(exp_dir, out_file):
    model_dir = exp_dir + '/models'
    glob_str = model_dir  + '/*ckpt*'
    ckpt_list = glob.glob(glob_str)
    ckpt_list = ['.'.join(ckpt.split('.')[:-1]) for ckpt in ckpt_list]
    print(colored('Processing {} performances in {}'.format(len(ckpt_list), exp_dir), "yellow"))
    all_performances_path = exp_dir + '/all_performances.tsv'
    performances_path = exp_dir + '/performances.tsv'
    subprocess.check_output(['touch', all_performances_path])
    config_path = exp_dir + '/config.json'
    results_path = exp_dir + '/performances.json'
    subprocess.call('bin/random_networks {} -E representations/random_networks_repr'.format(config_path), shell=True)
    subprocess.call('copy_original_representation {} -E representations/original_repr'.format(config_path), shell=True)

    for ckpt in ckpt_list:
        num_epochs = ckpt.split('-')[-1].split('.')[0]
        num_epochs, check = parse_num_epochs(num_epochs)
        if not check:
            continue
        print(colored('Processing model trained for {} epochs'.format(num_epochs), "green"))
        subprocess.call('fair_networks {} -E representations/fair_networks_repr -i {}'.format(config_path, ckpt),
                        shell=True)
        subprocess.call('test_representations {}'.format(exp_dir), shell=True)
        try:
            process_result(results_path, out_file, exp_dir + '_' + str(num_epochs))
        except Exception:
            print(colored("Error in process_result. Probable cause: representations with NaNs. Check performances.json.", "red"))
            subprocess.call('fair_networks {} -i {} -g variables'.format(config_path, ckpt),
                        shell=True)
            continue
        subprocess.call('process_performances {} > {}'.format(config_path, performances_path), shell=True)
        subprocess.call('printf "Epochs {}" >> {}'.format(num_epochs, all_performances_path), shell=True)
        subprocess.call('cat {} >> {}'.format(performances_path, all_performances_path), shell=True)
        subprocess.call('printf "====\n\n" >> {}'.format(all_performances_path), shell=True)
        subprocess.check_output(['mv', performances_path, 
                                exp_dir + '/performances{}.tsv'.format(num_epochs)])
        subprocess.check_output(['mv', results_path, 
                                exp_dir + '/performances{}.json'.format(num_epochs)])

if len(sys.argv) != 3:
    print('Wrong number of arguments.\nUsage: process_all [experiment_dir] [output_file_path]')

exp_main_dir = sys.argv[1]
out_file = sys.argv[2]
subprocess.call('printf "epochs,y_gap,s_gap,total_gap\n" >> {}'.format(out_file), shell=True)
all_exp_dirs = glob.glob(exp_main_dir + '/*')
num_cores = 10
executor = Parallel(n_jobs=num_cores)
executor(delayed(process_dir)(exp_dir, out_file) for exp_dir in all_exp_dirs)
